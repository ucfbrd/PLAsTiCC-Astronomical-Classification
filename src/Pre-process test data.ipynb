{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Users/georgyguryev/Documents/repos/6.867/PLAsTiCC-Astronomical-Classification/data/class_data/\"\n",
    "train = pd.read_csv(data_folder+'class_training_set.csv')\n",
    "meta_train = pd.read_csv(data_folder+'class_training_set_meta.csv')\n",
    "test = pd.read_csv(data_folder+'class_test_set.csv')\n",
    "meta_test = pd.read_csv(data_folder+'class_test_set_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp = {'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},{'coeff': 1, 'attr': 'abs'}],'kurtosis' : None, 'skewness' : None}\n",
    "#fcp = {'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},{'coeff': 1, 'attr': 'abs'}],'kurtosis' : None, 'skewness' : None,'absolute_sum_of_changes':None,'ar_coefficient':[{'coeff': 1, 'k': 5},{'coeff': 2, 'k': 5},{'coeff': 3, 'k': 5},{'coeff': 4, 'k': 5},{'coeff': 5, 'k': 5}],'partial_autocorrelation':[{'lag':5}],'linear_trend':[{'attr':'slope'}],'fft_aggregated':[{'aggtype':'centroid'}],'sample_entropy':None,'abs_energy':None,'last_location_of_maximum':None,'last_location_of_minimum':None,}\n",
    "def featurize(df):\n",
    "    df['flux_ratio_sq'] = np.power(df['flux'] / df['flux_err'], 2.0)\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    # train[detected==1, mjd_diff:=max(mjd)-min(mjd), by=object_id]\n",
    "\n",
    "\n",
    "    aggs = {\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq':['sum','skew'],\n",
    "        'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "    }\n",
    "\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = [\n",
    "        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "    ]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df['flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    # Add more features with \n",
    "    agg_df_ts = extract_features(df, column_id='object_id', column_sort='mjd', column_kind='passband', column_value = 'flux', default_fc_parameters = fcp, n_jobs=5)\n",
    "    # Add smart feature that is suggested here https://www.kaggle.com/c/PLAsTiCC-2018/discussion/69696#410538\n",
    "    # dt[detected==1, mjd_diff:=max(mjd)-min(mjd), by=object_id]\n",
    "    df_det = df[df['detected']==1].copy()\n",
    "\n",
    "    agg_df_mjd = extract_features(df_det, column_id='object_id', column_value = 'mjd', default_fc_parameters = {'maximum':None, 'minimum':None}, n_jobs=5)\n",
    "    agg_df_mjd['mjd_diff_det'] = agg_df_mjd['mjd__maximum'] - agg_df_mjd['mjd__minimum']\n",
    "    del agg_df_mjd['mjd__maximum'], agg_df_mjd['mjd__minimum']\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_mjd,left_index=True, right_index=True)\n",
    "    # tsfresh returns a dataframe with an index name='id'\n",
    "    #agg_df_ts.index.rename('object_id',inplace=True)\n",
    "    agg_df = pd.merge(agg_df, agg_df_ts,left_index=True, right_index=True)\n",
    "    return agg_df\n",
    "    #return agg_df_mjd,agg_df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 25/25 [00:05<00:00,  6.95it/s]\n",
      "Feature Extraction: 100%|██████████| 25/25 [00:00<00:00, 65.97it/s]\n"
     ]
    }
   ],
   "source": [
    "agg_train= featurize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes :  [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n"
     ]
    }
   ],
   "source": [
    "full_train = agg_train.reset_index().merge(\n",
    "    right=meta_train,\n",
    "    how='outer',\n",
    "    on='object_id'\n",
    ")\n",
    "\n",
    "if 'target' in full_train:\n",
    "    y = full_train['target']\n",
    "    del full_train['target']\n",
    "classes = sorted(y.unique())\n",
    "\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "print('Unique classes : ', classes)\n",
    "\n",
    "if 'object_id' in full_train:\n",
    "    oof_df = full_train[['object_id']]\n",
    "    del full_train['object_id'], full_train['distmod'], full_train['hostgal_specz']\n",
    "    del full_train['ra'], full_train['decl'], full_train['gal_l'],full_train['gal_b'],full_train['ddf']\n",
    "    \n",
    "train_mean = full_train.mean(axis=0)\n",
    "full_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df_, meta_, features, train_mean):\n",
    "    # Group by object id    \n",
    "    agg_ = featurize(df_)\n",
    "    # Merge with meta data\n",
    "    full_test = agg_.reset_index().merge(\n",
    "        right=meta_,\n",
    "        how='left',\n",
    "        on='object_id'\n",
    "    )\n",
    "\n",
    "    full_test = full_test.fillna(0)\n",
    "    return full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "Feature Extraction: 100%|██████████| 25/25 [00:02<00:00,  9.93it/s]\n",
      "Feature Extraction: 100%|██████████| 25/25 [00:00<00:00, 155.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        5000000 done in   0.1 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "chunks = 5000000\n",
    "remain_df = None\n",
    "\n",
    "for i_c, df in enumerate(pd.read_csv(data_folder+'class_test_set.csv', chunksize=chunks, iterator=True)):\n",
    "    unique_ids = np.unique(df['object_id'])\n",
    "    new_remain_df = df.loc[df['object_id'] == unique_ids[-1]].copy()\n",
    "    if remain_df is None:\n",
    "        df = df.loc[df['object_id'].isin(unique_ids[:-1])]\n",
    "    else:\n",
    "        df = pd.concat([remain_df, df.loc[df['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "    preds_df = pre_process(df_=df,\n",
    "                             meta_=meta_test,\n",
    "                             features=full_train.columns,\n",
    "                             train_mean=train_mean)\n",
    "\n",
    "    if i_c == 0:\n",
    "        preds_df.to_csv(data_folder+'test_data_clean.csv', header=True, mode='a', index=False)\n",
    "    else:\n",
    "        preds_df.to_csv(data_folder+'test_data_clean.csv', header=False, mode='a', index=False)\n",
    "\n",
    "    del preds_df\n",
    "    \n",
    "    print('%15d done in %5.1f minutes' % (chunks * (i_c + 1), (time.time() - start) / 60), flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4155154439616658"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
