{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youssefberrada/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn as sk\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = \"/Users/youssefberrada/Downloads/all/\"\n",
    "#train = pd.read_csv(data_folder+'training_set.csv')\n",
    "#meta_train = pd.read_csv(data_folder+'training_set_metadata.csv')\n",
    "\n",
    "data_folder = \"/Users/youssefberrada/Documents/GitHub/PLAsTiCC-Astronomical-Classification/data/class_data/\"\n",
    "train = pd.read_csv(data_folder+'class_training_set.csv')\n",
    "meta_train = pd.read_csv(data_folder+'class_training_set_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp = {'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},{'coeff': 1, 'attr': 'abs'}],'kurtosis' : None, 'skewness' : None}\n",
    "settings = ComprehensiveFCParameters()\n",
    "def featurize(df):\n",
    "    df['flux_ratio_sq'] = np.power(df['flux'] / df['flux_err'], 2.0)\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    # train[detected==1, mjd_diff:=max(mjd)-min(mjd), by=object_id]\n",
    "\n",
    "\n",
    "    aggs = {\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "        'detected': ['mean'],\n",
    "        'flux_ratio_sq':['sum','skew'],\n",
    "        'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "    }\n",
    "\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = [\n",
    "        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "    ]\n",
    "    agg_df.columns = new_columns\n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df['flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    # Add more features with \n",
    "    #agg_df_ts = extract_features(df, column_id='object_id', column_sort='mjd', column_kind='passband', column_value = 'flux', default_fc_parameters = fcp, n_jobs=4)\n",
    "    agg_df_ts = extract_features(df, column_id='object_id', column_sort='mjd', column_kind='passband', column_value = 'flux', default_fc_parameters=settings)\n",
    "    # Add smart feature that is suggested here https://www.kaggle.com/c/PLAsTiCC-2018/discussion/69696#410538\n",
    "    # dt[detected==1, mjd_diff:=max(mjd)-min(mjd), by=object_id]\n",
    "    df_det = df[df['detected']==1].copy()\n",
    "\n",
    "    #agg_df_mjd = extract_features(df_det, column_id='object_id', column_value = 'mjd', default_fc_parameters = {'maximum':None, 'minimum':None}, n_jobs=4)\n",
    "    agg_df_mjd = extract_features(df_det, column_id='object_id', column_value = 'mjd',default_fc_parameters=settings)\n",
    "    agg_df_mjd['mjd_diff_det'] = agg_df_mjd['mjd__maximum'] - agg_df_mjd['mjd__minimum']\n",
    "    del agg_df_mjd['mjd__maximum'], agg_df_mjd['mjd__minimum']\n",
    "    agg_df_ts = pd.merge(agg_df_ts, agg_df_mjd,left_index=True, right_index=True)\n",
    "    # tsfresh returns a dataframe with an index name='id'\n",
    "    #agg_df_ts.index.rename('object_id',inplace=True)\n",
    "    agg_df = pd.merge(agg_df, agg_df_ts,left_index=True, right_index=True)\n",
    "    return agg_df\n",
    "    #return agg_df_mjd,agg_df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train= featurize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_you = train[train.object_id == 713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 6/6 [00:00<00:00, 19.88it/s]\n"
     ]
    }
   ],
   "source": [
    "settings = ComprehensiveFCParameters()\n",
    "df = extract_features(train_you, column_id='object_id', column_sort='mjd', column_kind='passband', column_value = 'flux',default_fc_parameters=settings,n_jobs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>0__abs_energy</th>\n",
       "      <th>0__absolute_sum_of_changes</th>\n",
       "      <th>0__agg_autocorrelation__f_agg_\"mean\"</th>\n",
       "      <th>0__agg_autocorrelation__f_agg_\"median\"</th>\n",
       "      <th>0__agg_autocorrelation__f_agg_\"var\"</th>\n",
       "      <th>0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"</th>\n",
       "      <th>0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"</th>\n",
       "      <th>0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"</th>\n",
       "      <th>0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"</th>\n",
       "      <th>0__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"</th>\n",
       "      <th>...</th>\n",
       "      <th>5__time_reversal_asymmetry_statistic__lag_1</th>\n",
       "      <th>5__time_reversal_asymmetry_statistic__lag_2</th>\n",
       "      <th>5__time_reversal_asymmetry_statistic__lag_3</th>\n",
       "      <th>5__value_count__value_-inf</th>\n",
       "      <th>5__value_count__value_0</th>\n",
       "      <th>5__value_count__value_1</th>\n",
       "      <th>5__value_count__value_inf</th>\n",
       "      <th>5__value_count__value_nan</th>\n",
       "      <th>5__variance</th>\n",
       "      <th>5__variance_larger_than_standard_deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>4009.578484</td>\n",
       "      <td>202.081541</td>\n",
       "      <td>0.066937</td>\n",
       "      <td>0.132855</td>\n",
       "      <td>0.33905</td>\n",
       "      <td>13.729298</td>\n",
       "      <td>-0.930834</td>\n",
       "      <td>-3.456297</td>\n",
       "      <td>0.606837</td>\n",
       "      <td>14.509829</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.574897</td>\n",
       "      <td>43.008382</td>\n",
       "      <td>47.094082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.427194</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4764 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  0__abs_energy  0__absolute_sum_of_changes  \\\n",
       "id                                                    \n",
       "713         4009.578484                  202.081541   \n",
       "\n",
       "variable  0__agg_autocorrelation__f_agg_\"mean\"  \\\n",
       "id                                               \n",
       "713                                   0.066937   \n",
       "\n",
       "variable  0__agg_autocorrelation__f_agg_\"median\"  \\\n",
       "id                                                 \n",
       "713                                     0.132855   \n",
       "\n",
       "variable  0__agg_autocorrelation__f_agg_\"var\"  \\\n",
       "id                                              \n",
       "713                                   0.33905   \n",
       "\n",
       "variable  0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"  \\\n",
       "id                                                                           \n",
       "713                                               13.729298                  \n",
       "\n",
       "variable  0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"  \\\n",
       "id                                                                        \n",
       "713                                               -0.930834               \n",
       "\n",
       "variable  0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"  \\\n",
       "id                                                                       \n",
       "713                                               -3.456297              \n",
       "\n",
       "variable  0__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"  \\\n",
       "id                                                                        \n",
       "713                                                0.606837               \n",
       "\n",
       "variable  0__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"  \\\n",
       "id                                                                           \n",
       "713                                               14.509829                  \n",
       "\n",
       "variable                     ...                      \\\n",
       "id                           ...                       \n",
       "713                          ...                       \n",
       "\n",
       "variable  5__time_reversal_asymmetry_statistic__lag_1  \\\n",
       "id                                                      \n",
       "713                                        -62.574897   \n",
       "\n",
       "variable  5__time_reversal_asymmetry_statistic__lag_2  \\\n",
       "id                                                      \n",
       "713                                         43.008382   \n",
       "\n",
       "variable  5__time_reversal_asymmetry_statistic__lag_3  \\\n",
       "id                                                      \n",
       "713                                         47.094082   \n",
       "\n",
       "variable  5__value_count__value_-inf  5__value_count__value_0  \\\n",
       "id                                                              \n",
       "713                              0.0                      0.0   \n",
       "\n",
       "variable  5__value_count__value_1  5__value_count__value_inf  \\\n",
       "id                                                             \n",
       "713                           0.0                        0.0   \n",
       "\n",
       "variable  5__value_count__value_nan  5__variance  \\\n",
       "id                                                 \n",
       "713                             0.0    49.427194   \n",
       "\n",
       "variable  5__variance_larger_than_standard_deviation  \n",
       "id                                                    \n",
       "713                                              1.0  \n",
       "\n",
       "[1 rows x 4764 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "#modify to work with kfold\n",
    "#def smoteAdataset(Xig, yig, test_size=0.2, random_state=0):\n",
    "def smoteAdataset(Xig_train, yig_train, Xig_test, yig_test):\n",
    "    \n",
    "        \n",
    "    sm=SMOTE(random_state=2)\n",
    "    Xig_train_res, yig_train_res = sm.fit_sample(Xig_train, yig_train.ravel())\n",
    "\n",
    "        \n",
    "    return Xig_train_res, pd.Series(yig_train_res), Xig_test, pd.Series(yig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_importances(importances_):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    return importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_modeling_cross_validation(params,\n",
    "                                   full_train, \n",
    "                                   y, \n",
    "                                   classes, \n",
    "                                   class_weights, \n",
    "                                   nr_fold=12, \n",
    "                                   random_state=1):\n",
    "\n",
    "    # Compute weights\n",
    "    w = y.value_counts()\n",
    "    weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "   # print(weights)\n",
    "   # weights=class_weights\n",
    "    clfs = []\n",
    "    importances = pd.DataFrame()\n",
    "    folds = StratifiedKFold(n_splits=nr_fold, \n",
    "                            shuffle=True, \n",
    "                            random_state=random_state)\n",
    "    \n",
    "    oof_preds = np.zeros((len(full_train), np.unique(y).shape[0]))\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "        trn_x, trn_y = full_train.iloc[trn_], y.iloc[trn_]\n",
    "        val_x, val_y = full_train.iloc[val_], y.iloc[val_]\n",
    "        \n",
    "                \n",
    "        trn_xa, trn_y, val_xa, val_y=smoteAdataset(trn_x.values, trn_y.values, val_x.values, val_y.values)\n",
    "        trn_x=pd.DataFrame(data=trn_xa, columns=trn_x.columns)\n",
    "    \n",
    "        val_x=pd.DataFrame(data=val_xa, columns=val_x.columns)\n",
    "        \n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            trn_x, trn_y,\n",
    "            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "            eval_metric=lgbm_multi_weighted_logloss,\n",
    "            verbose=100,\n",
    "            early_stopping_rounds=50,\n",
    "            sample_weight=trn_y.map(weights)\n",
    "        )\n",
    "        clfs.append(clf)\n",
    "\n",
    "        oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "        print('no {}-fold loss: {}'.format(fold_ + 1, \n",
    "              multi_weighted_logloss(val_y, oof_preds[val_, :], \n",
    "                                     classes, class_weights)))\n",
    "    \n",
    "        imp_df = pd.DataFrame({\n",
    "                'feature': full_train.columns,\n",
    "                'gain': clf.feature_importances_,\n",
    "                'fold': [fold_ + 1] * len(full_train.columns),\n",
    "                })\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    score = multi_weighted_logloss(y_true=y, y_preds=oof_preds, \n",
    "                                   classes=classes, class_weights=class_weights)\n",
    "    print('MULTI WEIGHTED LOG LOSS: {:.5f}'.format(score))\n",
    "    df_importances = save_importances(importances_=importances)\n",
    "    df_importances.to_csv('lgbm_importances.csv', index=False)\n",
    "    \n",
    "    return clfs, score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
